{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-15T17:07:01.426604Z","iopub.execute_input":"2023-09-15T17:07:01.427899Z","iopub.status.idle":"2023-09-15T17:07:01.891926Z","shell.execute_reply.started":"2023-09-15T17:07:01.427849Z","shell.execute_reply":"2023-09-15T17:07:01.890524Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/mental-health-conversational-data/intents.json\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install tflearn","metadata":{"execution":{"iopub.status.busy":"2023-09-15T17:07:15.494316Z","iopub.execute_input":"2023-09-15T17:07:15.494990Z","iopub.status.idle":"2023-09-15T17:07:34.448665Z","shell.execute_reply.started":"2023-09-15T17:07:15.494945Z","shell.execute_reply":"2023-09-15T17:07:34.447521Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting tflearn\n  Downloading tflearn-0.5.0.tar.gz (107 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.3/107.3 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from tflearn) (1.23.5)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from tflearn) (1.16.0)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from tflearn) (9.5.0)\nBuilding wheels for collected packages: tflearn\n  Building wheel for tflearn (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for tflearn: filename=tflearn-0.5.0-py3-none-any.whl size=127283 sha256=a231a623243a2d6a0ae24c79402372d21119e352b09f6be819ec6959e7db3e0d\n  Stored in directory: /root/.cache/pip/wheels/55/fb/7b/e06204a0ceefa45443930b9a250cb5ebe31def0e4e8245a465\nSuccessfully built tflearn\nInstalling collected packages: tflearn\nSuccessfully installed tflearn-0.5.0\n","output_type":"stream"}]},{"cell_type":"code","source":"import nltk\nfrom nltk.stem.lancaster import LancasterStemmer\nimport numpy as np\nimport tflearn\nimport tensorflow as tf\nimport json\nimport pickle\nimport random","metadata":{"execution":{"iopub.status.busy":"2023-09-15T17:07:34.451267Z","iopub.execute_input":"2023-09-15T17:07:34.451612Z","iopub.status.idle":"2023-09-15T17:07:45.695480Z","shell.execute_reply.started":"2023-09-15T17:07:34.451584Z","shell.execute_reply":"2023-09-15T17:07:45.693926Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"**Loading all the content of the intents json file**","metadata":{}},{"cell_type":"code","source":"#Loading intents.json\nwith open('/kaggle/input/mental-health-conversational-data/intents.json') as intents:\n    data = json.load(intents)\n\nstemmer = LancasterStemmer()","metadata":{"execution":{"iopub.status.busy":"2023-09-15T17:07:45.697073Z","iopub.execute_input":"2023-09-15T17:07:45.697734Z","iopub.status.idle":"2023-09-15T17:07:45.710026Z","shell.execute_reply.started":"2023-09-15T17:07:45.697698Z","shell.execute_reply":"2023-09-15T17:07:45.708782Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"**Extracting all the information from the json file**","metadata":{}},{"cell_type":"code","source":"All_words = []\nAll_labels = []\nx_words = []\ny_words = []\n\nfor intent in data['intents']:    #openieng the file \n    for pattern in intent['patterns']:    \n        wrds = nltk.word_tokenize(pattern)    #tokeningzing the words \n        All_words.extend(wrds)\n        x_words.append(wrds)\n        y_words.append(intent['tag'])     #saving it \n\n        if intent['tag'] not in All_labels:\n            All_labels.append(intent['tag'])    #saivng all the tags","metadata":{"execution":{"iopub.status.busy":"2023-09-15T17:07:45.713654Z","iopub.execute_input":"2023-09-15T17:07:45.714369Z","iopub.status.idle":"2023-09-15T17:07:45.772524Z","shell.execute_reply.started":"2023-09-15T17:07:45.714326Z","shell.execute_reply":"2023-09-15T17:07:45.771234Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"data.keys()","metadata":{"execution":{"iopub.status.busy":"2023-09-15T17:07:45.774115Z","iopub.execute_input":"2023-09-15T17:07:45.774992Z","iopub.status.idle":"2023-09-15T17:07:45.783174Z","shell.execute_reply.started":"2023-09-15T17:07:45.774948Z","shell.execute_reply":"2023-09-15T17:07:45.782359Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"dict_keys(['intents'])"},"metadata":{}}]},{"cell_type":"code","source":"# data.values()","metadata":{"execution":{"iopub.status.busy":"2023-09-15T17:07:45.784574Z","iopub.execute_input":"2023-09-15T17:07:45.785260Z","iopub.status.idle":"2023-09-15T17:07:45.797094Z","shell.execute_reply.started":"2023-09-15T17:07:45.785190Z","shell.execute_reply":"2023-09-15T17:07:45.795654Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# **Let's Preprocess the Data!**","metadata":{}},{"cell_type":"markdown","source":"**Sreaming the data and Removing all the duplicates**","metadata":{}},{"cell_type":"code","source":"All_words = [stemmer.stem(w.lower()) for w in All_words if w not in \"?\"]\nAll_words = sorted(list(set(All_words)))\nAll_labels = sorted(All_labels)","metadata":{"execution":{"iopub.status.busy":"2023-09-15T17:07:45.798757Z","iopub.execute_input":"2023-09-15T17:07:45.799163Z","iopub.status.idle":"2023-09-15T17:07:45.834631Z","shell.execute_reply.started":"2023-09-15T17:07:45.799117Z","shell.execute_reply":"2023-09-15T17:07:45.833019Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"**Preparing the training data by using One hot encoding**","metadata":{}},{"cell_type":"code","source":"training = []\noutput = []\nout_empty = [0 for _ in range(len(All_labels))]\n\n# One hot encoding\nfor x, doc in enumerate(x_words):\n    Word_bag = []    #creating a bag of words \n    wrds = [stemmer.stem(w) for w in doc]\n    for w in All_words:\n        if w in wrds:\n            Word_bag.append(1)\n        else:\n            Word_bag.append(0)\n\n    Final_output= out_empty[:]\n    Final_output[All_labels.index(y_words[x])] = 1\n\n    training.append(Word_bag)\n    output.append(Final_output)\n\n\ntraining = np.array(training)\noutput = np.array(output)","metadata":{"execution":{"iopub.status.busy":"2023-09-15T17:07:45.836547Z","iopub.execute_input":"2023-09-15T17:07:45.837456Z","iopub.status.idle":"2023-09-15T17:07:45.909518Z","shell.execute_reply.started":"2023-09-15T17:07:45.837329Z","shell.execute_reply":"2023-09-15T17:07:45.908628Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# **Let's Create our Model Uisng Neural Networks!!**","metadata":{}},{"cell_type":"code","source":"net = tflearn.input_data(shape=[None, len(training[0])])\nnet = tflearn.fully_connected(net, 10)\nnet = tflearn.fully_connected(net, 10)\nnet = tflearn.fully_connected(net, 10)\nnet = tflearn.fully_connected(net, len(output[0]), activation='softmax')\nnet = tflearn.regression(net)\n\nmodel = tflearn.DNN(net)\nmodel.fit(training, output, n_epoch=500, batch_size=8, show_metric=True)\nmodel.save('model.tflearn')","metadata":{"execution":{"iopub.status.busy":"2023-09-15T17:07:45.910951Z","iopub.execute_input":"2023-09-15T17:07:45.911630Z","iopub.status.idle":"2023-09-15T17:09:01.750389Z","shell.execute_reply.started":"2023-09-15T17:07:45.911596Z","shell.execute_reply":"2023-09-15T17:09:01.749227Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Training Step: 14499  | total loss: \u001b[1m\u001b[32m0.16170\u001b[0m\u001b[0m | time: 0.086s\n| Adam | epoch: 500 | loss: 0.16170 - acc: 0.9591 -- iter: 224/232\nTraining Step: 14500  | total loss: \u001b[1m\u001b[32m0.15165\u001b[0m\u001b[0m | time: 0.089s\n| Adam | epoch: 500 | loss: 0.15165 - acc: 0.9632 -- iter: 232/232\n--\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Yaaaaay!!  Now we need to create a function(just like a bag) for the  predictions**","metadata":{}},{"cell_type":"code","source":"def bag_of_words(s, All_words):\n    Words_bag = [0 for _ in range(len(All_words))]\n    s_words = nltk.word_tokenize(s)\n    s_words = [stemmer.stem(word.lower()) for word in s_words]\n\n    for s_word in s_words:\n        for i, w in enumerate(All_words):\n            if w == s_word:\n                Words_bag[i] = 1\n\n    return np.array(Words_bag)","metadata":{"execution":{"iopub.status.busy":"2023-09-15T17:09:12.697039Z","iopub.execute_input":"2023-09-15T17:09:12.697478Z","iopub.status.idle":"2023-09-15T17:09:12.705305Z","shell.execute_reply.started":"2023-09-15T17:09:12.697446Z","shell.execute_reply":"2023-09-15T17:09:12.703970Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"**Now we need to create a function that ties everything together**","metadata":{}},{"cell_type":"code","source":"def chat():\n    while True:\n        inp = input(\"\\n\\nYou: \")\n        if inp.lower() == 'quit':\n            break\n    #Porbability of correct response \n        results = model.predict([bag_of_words(inp, All_words)])\n\n    # Picking the greatest number from probability\n        results_index = np.argmax(results)\n        tag = All_labels[results_index]\n        for tg in data['intents']:\n            if tg['tag'] == tag:\n                responses = tg['responses']\n                print(\"Bot:\\t\" + random.choice(responses))","metadata":{"execution":{"iopub.status.busy":"2023-09-15T17:09:13.974470Z","iopub.execute_input":"2023-09-15T17:09:13.974850Z","iopub.status.idle":"2023-09-15T17:09:13.981881Z","shell.execute_reply.started":"2023-09-15T17:09:13.974821Z","shell.execute_reply":"2023-09-15T17:09:13.980563Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"chat()","metadata":{"execution":{"iopub.status.busy":"2023-09-15T17:09:14.982917Z","iopub.execute_input":"2023-09-15T17:09:14.983369Z","iopub.status.idle":"2023-09-15T17:10:22.159300Z","shell.execute_reply.started":"2023-09-15T17:09:14.983335Z","shell.execute_reply":"2023-09-15T17:10:22.158304Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdin","text":"\n\nYou:  hi\n"},{"name":"stdout","text":"Bot:\tHi there. How are you feeling today?\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\n\nYou:  good\n"},{"name":"stdout","text":"Bot:\tThat's geat to hear. I'm glad you're feeling this way.\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\n\nYou:  what is menatal health\n"},{"name":"stdout","text":"Bot:\tMental health includes our emotional, psychological, and social well-being. It affects how we think, feel, and act. It also helps determine how we handle stress, relate to others, and make choices.\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\n\nYou:  quit\n"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}